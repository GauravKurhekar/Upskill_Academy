21.1-Calling one notebook from another
# Step1- create empdf in first notebook

# Create the Employee DataFrame
from pyspark.sql.types import StructType, StructField, StringType, IntegerType

# Define schema for Employee DataFrame
emp_schema = StructType([
    StructField("emp_id", IntegerType(), True),
    StructField("emp_name", StringType(), True),
    StructField("dept_id", IntegerType(), True)
])

# Sample employee data
emp_data = [
    (1, "Alice", 101),
    (2, "Bob", 102),
    (3, "Charlie", 101),
    (4, "David", 103)
]

# Create Employee DataFrame
emp_df = spark.createDataFrame(data=emp_data, schema=emp_schema)

# Display the Employee DataFrame
emp_df.show()

# Register as a temporary view for SQL or share with another notebook
#emp_df.createOrReplaceTempView("Employee")
----------------------
# Step 2- Create deptdf in second notebook

# Create the Department DataFrame

from pyspark.sql.types import StructType, StructField, StringType, IntegerType

# Define schema for Department DataFrame
dept_schema = StructType([
    StructField("dept_id", IntegerType(), True),
    StructField("dept_name", StringType(), True)
])

# Sample department data
dept_data = [
    (101, "HR"),
    (102, "Engineering"),
    (103, "Marketing")
]

# Create Department DataFrame
dept_df = spark.createDataFrame(data=dept_data, schema=dept_schema)

# Display the Department DataFrame
dept_df.show()

# Register as a temporary view for SQL or share with another notebook
#dept_df.createOrReplaceTempView("Department")
----------------------------------
# Step3- execute the run command and then join command
%run "./notebook1"

join_table = emp_df.join(dept_df, emp_df.dept_id == dept_df.dept_id, how = "inner")
display(join_table)
---------------------------
# Run Notebook1_Producer and Notebook2_Consumer
# Note- This will work only in Enterprise Edition

=================================================================
21.3- SQL Warehouse in Databricks
create database new_test_db;
use new_test_db;

CREATE TABLE IF NOT EXISTS employee (
    emp_id INT,
    emp_name STRING,
    department STRING,
    salary DOUBLE,
    join_date DATE
);
INSERT INTO employee VALUES
(101, 'Amit Sharma', 'Data Engineering', 85000, '2022-01-10'),
(102, 'Neha Verma', 'Analytics', 78000, '2021-11-05'),
(103, 'Rahul Mehta', 'Data Engineering', 92000, '2023-03-18'),
(104, 'Priya Singh', 'BI', 70000, '2020-07-25'),
(105, 'Suresh Kumar', 'Platform', 88000, '2022-09-12');
select * from employee;

==============================================================
21.4 Devops for databricks
# Code for Main Branch (Initial Version)

print("Welcome to Upskill Academy")
print("Learning Azure Data Engineering")

# Code for Sub-Branch (Feature / Change)
print("New lines are added")
print("will check if how code gets merge from main branch to sub-branch")
print("Git integration with Azure Databricks")


