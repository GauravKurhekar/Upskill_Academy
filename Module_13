# 13.5.1-Mounting via Access Key
spark.conf.set(
    "fs.azure.account.key.<storage-account>.dfs.core.windows.net",
    dbutils.secrets.get(scope="<scope>", key="<storage-account-access-key>"))

    # OR 

spark.conf.set(
    "fs.azure.account.key.<storage-account>.dfs.core.windows.net","<Access_Token>")
---------------------------------------------
13.5.2 -Mounting via SAS token
spark.conf.set("fs.azure.account.auth.type.<storage-account>.dfs.core.windows.net", "SAS")
spark.conf.set("fs.azure.sas.token.provider.type.<storage-account>.dfs.core.windows.net", "org.apache.hadoop.fs.azurebfs.sas.FixedSASTokenProvider")
spark.conf.set("fs.azure.sas.fixed.token.<storage-account>.dfs.core.windows.net", dbutils.secrets.get(scope="<scope>", key="<sas-token-key>"))

# OR 

spark.conf.set("fs.azure.account.auth.type.<storage-account>.dfs.core.windows.net", "SAS")
spark.conf.set("fs.azure.sas.token.provider.type.<storage-account>.dfs.core.windows.net", "org.apache.hadoop.fs.azurebfs.sas.FixedSASTokenProvider")
spark.conf.set("fs.azure.sas.fixed.token.<storage-account>.dfs.core.windows.net", "<sas-token-key>")
------------------------------------------------
13.3.6- Service Principal with OAuth2 (Recommended for Enterprise Use)
# Replace <client_id> in 3rd line using client_id with double quote("")
# Replace <client_secret> in 4th line with secret with double quote("")
# Replace <tenant_id> in 5th line without double quote("")
configs = {
  "fs.azure.account.auth.type": "OAuth",
  "fs.azure.account.oauth.provider.type": "org.apache.hadoop.fs.azurebfs.oauth2.ClientCredsTokenProvider",
  "fs.azure.account.oauth2.client.id": "<client_id>",
  "fs.azure.account.oauth2.client.secret": "<client_secret>",
  "fs.azure.account.oauth2.client.endpoint": "https://login.microsoftonline.com/<tenant_id>/oauth2/token"
}

dbutils.fs.mount(
  source = "abfss://<container_name>@<storage_account_name>.dfs.core.windows.net/",
  mount_point = "/mnt/<mount_name>",
  extra_configs = configs
)
----------------------------------------------------
# Secret Scope using Access key
spark.conf.set(
    "fs.azure.account.key.<storage-account>.dfs.core.windows.net",
    dbutils.secrets.get(scope="<scope>", key="<storage-account-access-key>"))
